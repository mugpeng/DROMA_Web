# meta calculation ----
#' Calculate meta-analysis for continuous vs continuous features
#' @param selected_pair List of paired data
#' @return Meta-analysis result object or NULL if insufficient data
metaCalConCon <- function(selected_pair){
  if(length(selected_pair) < 2) return(NULL)
  # test pairs one by one
  cal_list <- lapply(1:length(selected_pair), function(y){
    fea1_sel <- selected_pair[[y]][[1]]
    fea2_sel <- selected_pair[[y]][[2]]
    # Check for minimum length
    if(length(fea1_sel) < 3 || length(fea2_sel) < 3) return(NULL)
    cor_re <- tryCatch(
      cor.test(fea1_sel, fea2_sel,
               method = "pearson"),
      error = function(x){return(NULL)}
    )
    if(is.null(cor_re)) return(NULL)
    data.frame(
      p = cor_re$p.value,
      effect = cor_re$estimate,
      N = length(fea2_sel)
    )
  })
  cal_list <- cal_list[!sapply(cal_list, is.null)]
  if(length(cal_list) < 2) return(NULL)
  cal_re <- do.call(rbind, cal_list)
  cal_re$se <- sqrt((1 - cal_re$effect^2) / (cal_re$N - 2))
  cal_re$z <- 0.5 * log((1 + cal_re$effect) / (1 - cal_re$effect))  # Fisher's z 
  cal_re$se_z <- 1 / sqrt(cal_re$N - 3)         
  
  cal_meta_re <- tryCatch(
    suppressWarnings({metagen(TE = z, seTE = se_z, data = cal_re, sm = "Z",
                              control = list(maxiter = 2000,
                                             stepadj = 0.1,
                                             threshold = 0.000001)
    )}),
    error = function(x){return(NULL)}
  )
  cal_meta_re
}

#' Calculate meta-analysis for continuous vs discrete features
#' @param selected_pair List of paired data
#' @return Meta-analysis result object or NULL if insufficient data
metaCalConDis <- function(selected_pair){
  if(length(selected_pair) < 2) return(NULL)
  cal_list <- lapply(1:length(selected_pair), function(y){
    yes_drugs <- selected_pair[[y]][[1]]
    no_drugs <- selected_pair[[y]][[2]]
    
    # Check for minimum length
    if(length(yes_drugs) < 3 || length(no_drugs) < 3) return(NULL)
    
    wilcox_re <- tryCatch(
      wilcox.test(no_drugs, yes_drugs),
      error = function(x){return(NULL)}
    )
    if(is.null(wilcox_re)) return(NULL)
    
    cliff_delta <- tryCatch(
      cliff.delta(no_drugs, yes_drugs),
      error = function(x){return(NULL)}
    )
    if(is.null(cliff_delta)) return(NULL)
    
    data.frame(
      p = wilcox_re$p.value,
      effect = cliff_delta$estimate,
      N = length(yes_drugs) + length(no_drugs),
      n1 = length(yes_drugs),
      n2 = length(no_drugs)
    )
  })
  cal_list <- cal_list[!sapply(cal_list, is.null)]
  if(length(cal_list) < 2) return(NULL)
  cal_re <- do.call(rbind, cal_list)
  # Calculate standard error for Cliff's Delta
  cal_re$se <- sqrt((1 - cal_re$effect^2) * (cal_re$n1 + cal_re$n2 + 1) / 
                      (12 * cal_re$n1 * cal_re$n2))
  cal_meta_re <- tryCatch(
    suppressWarnings({meta_result <- metagen(TE = effect, 
                                             seTE = se, 
                                             data = cal_re,
                                             control = list(maxiter = 2000,
                                                            stepadj = 0.1,
                                                            threshold = 0.000001),
                                             sm = "CMD",  # Custom Mean Difference (using Cliff's Delta)
    )
    }),
    error = function(x){return(NULL)}
  )
  cal_meta_re
}

#' Calculate meta-analysis for discrete vs discrete features
#' @param selected_pair List of paired data
#' @return Meta-analysis result object or NULL if insufficient data
metaCalDisDis <- function(selected_pair) {
  # Check if we have enough pairs for meta-analysis
  if(length(selected_pair) < 2) return(NULL)
  
  # Calculate statistics for each pair
  cal_list <- lapply(1:length(selected_pair), function(y) {
    cont_table <- selected_pair[[y]]$cont_table
    
    # Skip if any cell has too few observations (e.g., < 3)
    if(any(cont_table < 3)) return(NULL)
    
    # Calculate odds ratio and its standard error
    tryCatch({
      # Extract values from contingency table
      a <- cont_table[1,1] # yes-yes
      b <- cont_table[1,2] # yes-no
      c <- cont_table[2,1] # no-yes
      d <- cont_table[2,2] # no-no
      
      # Calculate log odds ratio and its standard error
      log_or <- log((a * d)/(b * c))
      se_log_or <- sqrt(1/a + 1/b + 1/c + 1/d)
      
      # Calculate Fisher's exact test p-value
      fisher_test <- fisher.test(cont_table)
      
      data.frame(
        log_or = log_or,
        se = se_log_or,
        p = fisher_test$p.value,
        N = sum(cont_table)
      )
    }, error = function(x) NULL)
  })
  
  # Remove NULL results and combine
  cal_list <- cal_list[!sapply(cal_list, is.null)]
  if(length(cal_list) < 2) return(NULL)
  
  cal_re <- do.call(rbind, cal_list)
  
  # Perform meta-analysis using random effects model
  cal_meta_re <- tryCatch(
    suppressWarnings({
      metagen(TE = log_or,
              seTE = se,
              data = cal_re,
              sm = "OR", # Specify odds ratio as summary measure
              control = list(maxiter = 2000,
                             stepadj = 0.1,
                             threshold = 0.000001)
      )
    }),
    error = function(x) NULL
  )
  
  cal_meta_re
}

# Others ----
#' Format seconds into a human-readable time string
#' @param seconds Number of seconds
#' @return Formatted time string
format_time <- function(seconds) {
  if (seconds < 60) {
    return(sprintf("%d seconds", round(seconds)))
  } else if (seconds < 3600) {
    minutes <- floor(seconds / 60)
    remaining_seconds <- round(seconds %% 60)
    return(sprintf("%d minutes %d seconds", minutes, remaining_seconds))
  } else {
    hours <- floor(seconds / 3600)
    remaining_minutes <- floor((seconds %% 3600) / 60)
    return(sprintf("%d hours %d minutes", hours, remaining_minutes))
  }
}

#' Calculate estimated time remaining based on progress
#' @param done Number of items processed
#' @param total Total number of items
#' @param elapsed_time Time elapsed so far in seconds
#' @return Estimated time remaining in seconds
estimate_time_remaining <- function(done, total, elapsed_time) {
  if (done == 0) return(Inf)
  rate <- elapsed_time / done
  remaining <- total - done
  remaining * rate
}

# Get pair data ----
#' Pair continuous with continuous data
#' @param myOmics First feature data list
#' @param myDrugs Second feature data list
#' @return List of paired data
pairDrugOmic_batch1 <- function(myOmics, myDrugs){
  pair_list2 <- lapply(1:length(myOmics), function(x){
    omic_sel <- myOmics[[x]]
    pair_list <- lapply(1:length(myDrugs), function(y){
      drug_sel <- myDrugs[[y]]
      omic_sel <- na.omit(omic_sel); drug_sel <- na.omit(drug_sel)
      if(length(na.omit(omic_sel)) == 0 | length(na.omit(drug_sel)) == 0){ return(NULL) }
      intersected_cells <- intersect(names(omic_sel), names(drug_sel))
      if(length(intersected_cells) < 3) return(NULL)  # Ensure minimum sample size
      omic_sel <- omic_sel[match(intersected_cells, names(omic_sel))]
      drug_sel <- drug_sel[match(intersected_cells, names(drug_sel))]
      list("omic" = omic_sel,
           "drug" = drug_sel)
    })
    names(pair_list) <- paste0(names(myOmics)[x], "_",
                               names(myDrugs))
    pair_list
  })
  pair_list2 <- unlist(pair_list2, recursive = F)
  pair_list2 <- pair_list2[!sapply(pair_list2, is.null)]
  pair_list2
}

#' Pair discrete with continuous data
#' @param myOmics Discrete feature data list
#' @param myDrugs Continuous feature data list
#' @return List of paired data
pairDrugOmic_batch2 <- function(myOmics, myDrugs){
  pair_list2 <- lapply(1:length(myOmics), function(x){
    omic_sel <- myOmics[[x]]
    pair_list <- lapply(1:length(myDrugs), function(y){
      drug_sel <- myDrugs[[y]]
      yes_drugs <- na.omit(drug_sel[names(drug_sel) %in% omic_sel])
      no_drugs <- na.omit(drug_sel[!names(drug_sel) %in% omic_sel])
      if(length(yes_drugs) < 3 | length(no_drugs) < 3){ 
        return(NULL)
      }
      list(yes = yes_drugs,
           no = no_drugs)
    })
    names(pair_list) <- paste0(names(myOmics)[x], "_",
                               names(myDrugs))
    pair_list
  })
  pair_list2 <- unlist(pair_list2, recursive = F)
  pair_list2 <- pair_list2[!sapply(pair_list2, is.null)]
  return(pair_list2)
}

#' Pair discrete with discrete data
#' @param my_feas1 First discrete feature data list
#' @param my_feas2 Second discrete feature data list
#' @param feature1_type Type of first feature
#' @param feature2_type Type of second feature
#' @param cells_search Reference data for all cells
#' @return List of paired data with contingency tables
pairDrugOmic_batch3 <- function(my_feas1, my_feas2, 
                                feature1_type, feature2_type,
                                cells_search) {
  # Create pairs list across all features in dataset 1
  pair_list3 <- lapply(1:length(my_feas1), function(x) {
    fea1_sel <- my_feas1[[x]]
    # For each feature in dataset 1, compare with all features in dataset 2
    pair_list <- lapply(1:length(my_feas2), function(y) {
      fea2_sel <- my_feas2[[y]]
      # Skip if either feature has no data
      if (length(fea1_sel) == 0 || length(fea2_sel) == 0) {
        return(NULL)
      }
      
      # Get relevant cell/sample universe
      cells_search_sel <- cells_search[cells_search$type %in% c(feature1_type, feature2_type) &
                                         cells_search$datasets %in% c(names(my_feas1)[x], names(my_feas2)[y]),]
      all_cells <- unique(cells_search_sel$cells)
      
      # Create 2x2 contingency table
      yes_yes <- length(intersect(fea1_sel, fea2_sel))
      yes_no <- length(fea1_sel) - yes_yes
      no_yes <- length(fea2_sel) - yes_yes
      no_no <- length(all_cells) - (yes_yes + yes_no + no_yes)
      
      # Skip if any cell count is too low or negative (invalid)
      if (any(c(yes_yes, yes_no, no_yes, no_no) < 3)) {
        return(NULL)
      }
      
      # Create contingency table
      cont_table <- matrix(
        c(yes_yes, yes_no, 
          no_yes, no_no),
        nrow = 2,
        dimnames = list(
          Feature1 = c("Yes", "No"),
          Feature2 = c("Yes", "No")
        )
      )
      
      list(
        "cont_table" = cont_table
      )
    })
    
    names(pair_list) <- paste0(names(my_feas1)[x], "_",
                               names(my_feas2))
    pair_list
  })
  
  # Flatten list and remove NULL entries
  pair_list3 <- unlist(pair_list3, recursive = FALSE)
  pair_list3 <- pair_list3[!sapply(pair_list3, is.null)]
  
  return(pair_list3)
}

# Main function----
#' Batch analysis of feature relationships
#' 
#' Analyzes relationships between two feature types across multiple samples and datasets.
#' Performs appropriate statistical tests and meta-analysis based on feature types.
#' 
#' @param feature1_type Type of first feature ("mRNA", "cnv", "meth", etc.)
#' @param feature1_name Name of first feature
#' @param feature2_type Type of second feature to compare against
#' @param data_type Data type filter ("all", "cell", "PDO", etc.)
#' @param tumor_type Tumor type filter ("all" or specific tumor types)
#' @param cores Number of CPU cores to use for parallel processing
#' @param progress_callback Optional callback function for progress updates
#' @return Data frame with meta-analysis results (p_value, effect_size, N, name)
#' @export
BatchFindSigFeaturesPlus <- function(feature1_type, 
                                     feature1_name, 
                                     feature2_type,
                                     data_type = "all",
                                     tumor_type = "all",
                                     cores = 1,
                                     progress_callback = NULL,
                                     test_top_100 = FALSE
) {
  # Validate inputs
  valid_feature_types <- c("mRNA", "cnv", "meth", "proteinrppa", "proteinms",
                           "drug", "mutation_gene", "mutation_site", "fusion")
  
  if(!all(c(feature1_type, feature2_type) %in% valid_feature_types)) {
    stop(paste0("The selected feature type doesn't exist. Please choose from: ",
                paste(valid_feature_types, collapse = ", ")))
  }
  
  valid_data_types <- c("all", "cell", "PDC", "PDO", "PDX")
  if(!data_type %in% valid_data_types) {
    stop(paste0("Invalid data_type. Please choose from: ",
                paste(valid_data_types, collapse = ", ")))
  }
  
  # Track timing for progress updates
  start_time <- Sys.time()
  
  # Determine feature types
  continuous_types <- c("drug", "cnv", "proteinrppa", 
                        "proteinms", "meth", "mRNA")
  is_continuous1 <- feature1_type %in% continuous_types
  is_continuous2 <- feature2_type %in% continuous_types
  
  # Get selected specific feature1 data
  selected_feas1 <- selFeatures(feature1_type, feature1_name, data_type, tumor_type) 
  if(is.null(selected_feas1) || length(selected_feas1) == 0) {
    stop("No data available for the selected feature 1.")
  }
  
  # Filter selected_feas1 to ensure each dataset has at least 3 samples
  selected_feas1 <- lapply(selected_feas1, function(dataset) {
    # Remove NA values
    dataset <- na.omit(dataset)
    # Check if the dataset has at least 3 samples after NA removal
    if (length(dataset) < 3) {
      return(NULL)
    } else {
      return(dataset)
    }
  })
  
  # Remove NULL entries
  selected_feas1 <- selected_feas1[!sapply(selected_feas1, is.null)]
  
  # Check if any data remains after filtering
  if(length(selected_feas1) == 0) {
    stop(paste0("No sufficient data available for feature '", feature1_name, 
                "' of type '", feature1_type, "'. Each dataset needs at least 3 samples. ",
                "Please try with a different feature."))
  }
  
  # Get compared feature2 vector
  feas_search_sel <- feas_search[feas_search$type %in% feature2_type,]
  if(test_top_100 & nrow(feas_search_sel) > 100){
    feas_search_sel <- feas_search_sel[1:100,]
  }
  if(nrow(feas_search_sel) == 0) {
    stop("No features found for the selected feature 2 type.")
  }
  
  # Define the worker function
  worker_function <- function(x) {
    results <- tryCatch({
      feature2_name <- feas_search_sel[x,1]
      selected_feas2 <- selFeatures(feature2_type, feature2_name, data_type, tumor_type) 
      
      if (is.null(selected_feas2) || length(selected_feas2) == 0) return(NULL)
      
      # Filter selected_feas2 to ensure each dataset has at least 3 samples
      selected_feas2 <- lapply(selected_feas2, function(dataset) {
        # Remove NA values
        dataset <- na.omit(dataset)
        # Check if the dataset has at least 3 samples after NA removal
        if (length(dataset) < 3) {
          return(NULL)
        } else {
          return(dataset)
        }
      })
      
      # Remove NULL entries
      selected_feas2 <- selected_feas2[!sapply(selected_feas2, is.null)]
      
      # Skip if no sufficient data remains after filtering
      if(length(selected_feas2) == 0) return(NULL)
      
      # do statistics test based on four circumstances 
      # con vs con ----
      if (is_continuous1 && is_continuous2) {
        selected_pair <- pairDrugOmic_batch1(selected_feas1, selected_feas2)
        cal_meta_re <- metaCalConCon(selected_pair)
        # dis vs con ----
      } else if ((is_continuous1 && !is_continuous2) || (!is_continuous1 && is_continuous2)) {
        if (is_continuous1 && !is_continuous2){
          selected_pair <- pairDrugOmic_batch2(selected_feas2, selected_feas1)
        } else {
          selected_pair <- pairDrugOmic_batch2(selected_feas1, selected_feas2)
        } 
        cal_meta_re <- metaCalConDis(selected_pair)  
        # dis vs dis ----
      } else {
        selected_pair <- pairDrugOmic_batch3(selected_feas1, selected_feas2, 
                                             feature1_type = feature1_type,
                                             feature2_type = feature2_type,
                                             cells_search = cells_search)
        cal_meta_re <- metaCalDisDis(selected_pair)  
      }
      
      if(is.null(cal_meta_re)) return(NULL)
      results <- data.frame(
        p_value = cal_meta_re[["pval.random"]],
        effect_size = cal_meta_re[["TE.random"]],
        N = length(cal_meta_re[["studlab"]])
      )
    }, error = function(e) {
      # Log error but continue processing
      message(sprintf("Error processing feature %d: %s", x, e$message))
      NULL
    })
    
    # Update progress if callback provided
    if(!is.null(progress_callback)) {
      progress_callback(x, nrow(feas_search_sel), 
                        difftime(Sys.time(), start_time, units = "secs"))
    }
    
    return(results)
  }
  
  # Use parallel processing if cores > 1
  if (cores > 1) {
    # Initialize snowfall
    sfInit(parallel = TRUE, cpus = cores)
    
    # Export required data and functions
    sfExport("selected_feas1", "feas_search_sel", 
             "is_continuous1", "is_continuous2",
             "feature1_type", "feature2_type", "cells_search", "fea_list",
             "start_time")
    
    # Export functions
    sfExport("selFeatures", "pairDrugOmic_batch1", "pairDrugOmic_batch2", 
             "pairDrugOmic_batch3", "metaCalConCon", "metaCalConDis", "metaCalDisDis")
    
    # Export specific data
    feas_sel_vec <- fea_list[[feature2_type]]
    feas_sel_vec2 <- paste0(feas_sel_vec, "_", feature2_type)
    sfExport(list = feas_sel_vec2)
    
    # Load required packages on worker nodes
    sfLibrary(meta)
    sfLibrary(metafor)
    sfLibrary(effsize)
    
    # Run parallel computation
    cal_re_list <- sfLapply(1:nrow(feas_search_sel), worker_function)
    
    # Clean up snowfall
    sfStop()
  } else {
    # Run sequential computation
    cal_re_list <- lapply(1:nrow(feas_search_sel), worker_function)
  }
  
  # Process results
  valid_results <- !sapply(cal_re_list, is.null)
  fea_names <- feas_search_sel$name[valid_results]
  cal_re_list <- cal_re_list[valid_results]
  
  if (length(cal_re_list) == 0) {
    stop("No valid results found for the selected features. Please try others.")
  }
  
  cal_re_df <- do.call(rbind, cal_re_list)
  cal_re_df$name <- fea_names
  
  # Log completion
  total_time <- difftime(Sys.time(), start_time, units = "secs")
  message(sprintf("Analysis completed in %s", format_time(as.numeric(total_time))))
  message(sprintf("Found %d significant associations out of %d features.", 
                  sum(cal_re_df$p_value < 0.05), nrow(cal_re_df)))
  
  return(cal_re_df)
}

